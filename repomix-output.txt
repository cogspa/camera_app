This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2024-12-06T14:38:06.188Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repomix, visit: https://github.com/yamadashy/repomix

================================================================
Repository Structure
================================================================
.repomixignore
project/.bolt/config.json
project/.git/COMMIT_EDITMSG
project/.git/config
project/.git/description
project/.git/FETCH_HEAD
project/.git/HEAD
project/.git/hooks/applypatch-msg.sample
project/.git/hooks/commit-msg.sample
project/.git/hooks/fsmonitor-watchman.sample
project/.git/hooks/post-update.sample
project/.git/hooks/pre-applypatch.sample
project/.git/hooks/pre-commit.sample
project/.git/hooks/pre-merge-commit.sample
project/.git/hooks/pre-push.sample
project/.git/hooks/pre-rebase.sample
project/.git/hooks/pre-receive.sample
project/.git/hooks/prepare-commit-msg.sample
project/.git/hooks/push-to-checkout.sample
project/.git/hooks/sendemail-validate.sample
project/.git/hooks/update.sample
project/.git/info/exclude
project/.git/logs/HEAD
project/.git/logs/refs/heads/master
project/.git/logs/refs/remotes/origin/main
project/.git/logs/refs/remotes/origin/master
project/.git/logs/refs/stash
project/.git/ORIG_HEAD
project/.git/refs/heads/master
project/.git/refs/remotes/origin/main
project/.git/refs/remotes/origin/master
project/.git/refs/stash
project/.gitignore
project/index.html
project/index.js
project/main.js
project/package.json
project/postcss.config.js
project/README.md
project/src/camera-selector.js
project/src/components/diagnostic-panel.js
project/src/face-tracker.js
project/src/main.js
project/src/style.css
project/src/utils/diagnostics.js
project/src/webcam.js
project/tailwind.config.js

================================================================
Repository Files
================================================================

================
File: .repomixignore
================
samurai
node_modules

================
File: project/.bolt/config.json
================
{
  "template": "node"
}

================
File: project/.git/COMMIT_EDITMSG
================
Fixed video and overlay flipping issues for better tracking alignment

================
File: project/.git/config
================
[core]
	repositoryformatversion = 0
	filemode = false
	bare = false
	logallrefupdates = true
	symlinks = false
	ignorecase = true
[remote "origin"]
	url = https://github.com/cogspa/camera_app.git
	fetch = +refs/heads/*:refs/remotes/origin/*
[branch "master"]
	remote = origin
	merge = refs/heads/master

================
File: project/.git/description
================
Unnamed repository; edit this file 'description' to name the repository.

================
File: project/.git/FETCH_HEAD
================
d195c0db4bbaea2965a7f24a67179939c3e6f50b		branch 'master' of https://github.com/cogspa/camera_app
e583ca9ed7b4f6f45fca9b83bcd3e288c8eb8ea2	not-for-merge	branch 'main' of https://github.com/cogspa/camera_app

================
File: project/.git/HEAD
================
ref: refs/heads/master

================
File: project/.git/hooks/applypatch-msg.sample
================
#!/bin/sh
#
# An example hook script to check the commit log message taken by
# applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.  The hook is
# allowed to edit the commit message file.
#
# To enable this hook, rename this file to "applypatch-msg".

. git-sh-setup
commitmsg="$(git rev-parse --git-path hooks/commit-msg)"
test -x "$commitmsg" && exec "$commitmsg" ${1+"$@"}
:

================
File: project/.git/hooks/commit-msg.sample
================
#!/bin/sh
#
# An example hook script to check the commit log message.
# Called by "git commit" with one argument, the name of the file
# that has the commit message.  The hook should exit with non-zero
# status after issuing an appropriate message if it wants to stop the
# commit.  The hook is allowed to edit the commit message file.
#
# To enable this hook, rename this file to "commit-msg".

# Uncomment the below to add a Signed-off-by line to the message.
# Doing this in a hook is a bad idea in general, but the prepare-commit-msg
# hook is more suited to it.
#
# SOB=$(git var GIT_AUTHOR_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# grep -qs "^$SOB" "$1" || echo "$SOB" >> "$1"

# This example catches duplicate Signed-off-by lines.

test "" = "$(grep '^Signed-off-by: ' "$1" |
	 sort | uniq -c | sed -e '/^[ 	]*1[ 	]/d')" || {
	echo >&2 Duplicate Signed-off-by lines.
	exit 1
}

================
File: project/.git/hooks/fsmonitor-watchman.sample
================
#!/usr/bin/perl

use strict;
use warnings;
use IPC::Open2;

# An example hook script to integrate Watchman
# (https://facebook.github.io/watchman/) with git to speed up detecting
# new and modified files.
#
# The hook is passed a version (currently 2) and last update token
# formatted as a string and outputs to stdout a new update token and
# all files that have been modified since the update token. Paths must
# be relative to the root of the working tree and separated by a single NUL.
#
# To enable this hook, rename this file to "query-watchman" and set
# 'git config core.fsmonitor .git/hooks/query-watchman'
#
my ($version, $last_update_token) = @ARGV;

# Uncomment for debugging
# print STDERR "$0 $version $last_update_token\n";

# Check the hook interface version
if ($version ne 2) {
	die "Unsupported query-fsmonitor hook version '$version'.\n" .
	    "Falling back to scanning...\n";
}

my $git_work_tree = get_working_dir();

my $retry = 1;

my $json_pkg;
eval {
	require JSON::XS;
	$json_pkg = "JSON::XS";
	1;
} or do {
	require JSON::PP;
	$json_pkg = "JSON::PP";
};

launch_watchman();

sub launch_watchman {
	my $o = watchman_query();
	if (is_work_tree_watched($o)) {
		output_result($o->{clock}, @{$o->{files}});
	}
}

sub output_result {
	my ($clockid, @files) = @_;

	# Uncomment for debugging watchman output
	# open (my $fh, ">", ".git/watchman-output.out");
	# binmode $fh, ":utf8";
	# print $fh "$clockid\n@files\n";
	# close $fh;

	binmode STDOUT, ":utf8";
	print $clockid;
	print "\0";
	local $, = "\0";
	print @files;
}

sub watchman_clock {
	my $response = qx/watchman clock "$git_work_tree"/;
	die "Failed to get clock id on '$git_work_tree'.\n" .
		"Falling back to scanning...\n" if $? != 0;

	return $json_pkg->new->utf8->decode($response);
}

sub watchman_query {
	my $pid = open2(\*CHLD_OUT, \*CHLD_IN, 'watchman -j --no-pretty')
	or die "open2() failed: $!\n" .
	"Falling back to scanning...\n";

	# In the query expression below we're asking for names of files that
	# changed since $last_update_token but not from the .git folder.
	#
	# To accomplish this, we're using the "since" generator to use the
	# recency index to select candidate nodes and "fields" to limit the
	# output to file names only. Then we're using the "expression" term to
	# further constrain the results.
	my $last_update_line = "";
	if (substr($last_update_token, 0, 1) eq "c") {
		$last_update_token = "\"$last_update_token\"";
		$last_update_line = qq[\n"since": $last_update_token,];
	}
	my $query = <<"	END";
		["query", "$git_work_tree", {$last_update_line
			"fields": ["name"],
			"expression": ["not", ["dirname", ".git"]]
		}]
	END

	# Uncomment for debugging the watchman query
	# open (my $fh, ">", ".git/watchman-query.json");
	# print $fh $query;
	# close $fh;

	print CHLD_IN $query;
	close CHLD_IN;
	my $response = do {local $/; <CHLD_OUT>};

	# Uncomment for debugging the watch response
	# open ($fh, ">", ".git/watchman-response.json");
	# print $fh $response;
	# close $fh;

	die "Watchman: command returned no output.\n" .
	"Falling back to scanning...\n" if $response eq "";
	die "Watchman: command returned invalid output: $response\n" .
	"Falling back to scanning...\n" unless $response =~ /^\{/;

	return $json_pkg->new->utf8->decode($response);
}

sub is_work_tree_watched {
	my ($output) = @_;
	my $error = $output->{error};
	if ($retry > 0 and $error and $error =~ m/unable to resolve root .* directory (.*) is not watched/) {
		$retry--;
		my $response = qx/watchman watch "$git_work_tree"/;
		die "Failed to make watchman watch '$git_work_tree'.\n" .
		    "Falling back to scanning...\n" if $? != 0;
		$output = $json_pkg->new->utf8->decode($response);
		$error = $output->{error};
		die "Watchman: $error.\n" .
		"Falling back to scanning...\n" if $error;

		# Uncomment for debugging watchman output
		# open (my $fh, ">", ".git/watchman-output.out");
		# close $fh;

		# Watchman will always return all files on the first query so
		# return the fast "everything is dirty" flag to git and do the
		# Watchman query just to get it over with now so we won't pay
		# the cost in git to look up each individual file.
		my $o = watchman_clock();
		$error = $output->{error};

		die "Watchman: $error.\n" .
		"Falling back to scanning...\n" if $error;

		output_result($o->{clock}, ("/"));
		$last_update_token = $o->{clock};

		eval { launch_watchman() };
		return 0;
	}

	die "Watchman: $error.\n" .
	"Falling back to scanning...\n" if $error;

	return 1;
}

sub get_working_dir {
	my $working_dir;
	if ($^O =~ 'msys' || $^O =~ 'cygwin') {
		$working_dir = Win32::GetCwd();
		$working_dir =~ tr/\\/\//;
	} else {
		require Cwd;
		$working_dir = Cwd::cwd();
	}

	return $working_dir;
}

================
File: project/.git/hooks/post-update.sample
================
#!/bin/sh
#
# An example hook script to prepare a packed repository for use over
# dumb transports.
#
# To enable this hook, rename this file to "post-update".

exec git update-server-info

================
File: project/.git/hooks/pre-applypatch.sample
================
#!/bin/sh
#
# An example hook script to verify what is about to be committed
# by applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-applypatch".

. git-sh-setup
precommit="$(git rev-parse --git-path hooks/pre-commit)"
test -x "$precommit" && exec "$precommit" ${1+"$@"}
:

================
File: project/.git/hooks/pre-commit.sample
================
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git commit" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message if
# it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-commit".

if git rev-parse --verify HEAD >/dev/null 2>&1
then
	against=HEAD
else
	# Initial commit: diff against an empty tree object
	against=$(git hash-object -t tree /dev/null)
fi

# If you want to allow non-ASCII filenames set this variable to true.
allownonascii=$(git config --type=bool hooks.allownonascii)

# Redirect output to stderr.
exec 1>&2

# Cross platform projects tend to avoid non-ASCII filenames; prevent
# them from being added to the repository. We exploit the fact that the
# printable range starts at the space character and ends with tilde.
if [ "$allownonascii" != "true" ] &&
	# Note that the use of brackets around a tr range is ok here, (it's
	# even required, for portability to Solaris 10's /usr/bin/tr), since
	# the square bracket bytes happen to fall in the designated range.
	test $(git diff --cached --name-only --diff-filter=A -z $against |
	  LC_ALL=C tr -d '[ -~]\0' | wc -c) != 0
then
	cat <<\EOF
Error: Attempt to add a non-ASCII file name.

This can cause problems if you want to work with people on other platforms.

To be portable it is advisable to rename the file.

If you know what you are doing you can disable this check using:

  git config hooks.allownonascii true
EOF
	exit 1
fi

# If there are whitespace errors, print the offending file names and fail.
exec git diff-index --check --cached $against --

================
File: project/.git/hooks/pre-merge-commit.sample
================
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git merge" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message to
# stderr if it wants to stop the merge commit.
#
# To enable this hook, rename this file to "pre-merge-commit".

. git-sh-setup
test -x "$GIT_DIR/hooks/pre-commit" &&
        exec "$GIT_DIR/hooks/pre-commit"
:

================
File: project/.git/hooks/pre-push.sample
================
#!/bin/sh

# An example hook script to verify what is about to be pushed.  Called by "git
# push" after it has checked the remote status, but before anything has been
# pushed.  If this script exits with a non-zero status nothing will be pushed.
#
# This hook is called with the following parameters:
#
# $1 -- Name of the remote to which the push is being done
# $2 -- URL to which the push is being done
#
# If pushing without using a named remote those arguments will be equal.
#
# Information about the commits which are being pushed is supplied as lines to
# the standard input in the form:
#
#   <local ref> <local oid> <remote ref> <remote oid>
#
# This sample shows how to prevent push of commits where the log message starts
# with "WIP" (work in progress).

remote="$1"
url="$2"

zero=$(git hash-object --stdin </dev/null | tr '[0-9a-f]' '0')

while read local_ref local_oid remote_ref remote_oid
do
	if test "$local_oid" = "$zero"
	then
		# Handle delete
		:
	else
		if test "$remote_oid" = "$zero"
		then
			# New branch, examine all commits
			range="$local_oid"
		else
			# Update to existing branch, examine new commits
			range="$remote_oid..$local_oid"
		fi

		# Check for WIP commit
		commit=$(git rev-list -n 1 --grep '^WIP' "$range")
		if test -n "$commit"
		then
			echo >&2 "Found WIP commit in $local_ref, not pushing"
			exit 1
		fi
	fi
done

exit 0

================
File: project/.git/hooks/pre-rebase.sample
================
#!/bin/sh
#
# Copyright (c) 2006, 2008 Junio C Hamano
#
# The "pre-rebase" hook is run just before "git rebase" starts doing
# its job, and can prevent the command from running by exiting with
# non-zero status.
#
# The hook is called with the following parameters:
#
# $1 -- the upstream the series was forked from.
# $2 -- the branch being rebased (or empty when rebasing the current branch).
#
# This sample shows how to prevent topic branches that are already
# merged to 'next' branch from getting rebased, because allowing it
# would result in rebasing already published history.

publish=next
basebranch="$1"
if test "$#" = 2
then
	topic="refs/heads/$2"
else
	topic=`git symbolic-ref HEAD` ||
	exit 0 ;# we do not interrupt rebasing detached HEAD
fi

case "$topic" in
refs/heads/??/*)
	;;
*)
	exit 0 ;# we do not interrupt others.
	;;
esac

# Now we are dealing with a topic branch being rebased
# on top of master.  Is it OK to rebase it?

# Does the topic really exist?
git show-ref -q "$topic" || {
	echo >&2 "No such branch $topic"
	exit 1
}

# Is topic fully merged to master?
not_in_master=`git rev-list --pretty=oneline ^master "$topic"`
if test -z "$not_in_master"
then
	echo >&2 "$topic is fully merged to master; better remove it."
	exit 1 ;# we could allow it, but there is no point.
fi

# Is topic ever merged to next?  If so you should not be rebasing it.
only_next_1=`git rev-list ^master "^$topic" ${publish} | sort`
only_next_2=`git rev-list ^master           ${publish} | sort`
if test "$only_next_1" = "$only_next_2"
then
	not_in_topic=`git rev-list "^$topic" master`
	if test -z "$not_in_topic"
	then
		echo >&2 "$topic is already up to date with master"
		exit 1 ;# we could allow it, but there is no point.
	else
		exit 0
	fi
else
	not_in_next=`git rev-list --pretty=oneline ^${publish} "$topic"`
	/usr/bin/perl -e '
		my $topic = $ARGV[0];
		my $msg = "* $topic has commits already merged to public branch:\n";
		my (%not_in_next) = map {
			/^([0-9a-f]+) /;
			($1 => 1);
		} split(/\n/, $ARGV[1]);
		for my $elem (map {
				/^([0-9a-f]+) (.*)$/;
				[$1 => $2];
			} split(/\n/, $ARGV[2])) {
			if (!exists $not_in_next{$elem->[0]}) {
				if ($msg) {
					print STDERR $msg;
					undef $msg;
				}
				print STDERR " $elem->[1]\n";
			}
		}
	' "$topic" "$not_in_next" "$not_in_master"
	exit 1
fi

<<\DOC_END

This sample hook safeguards topic branches that have been
published from being rewound.

The workflow assumed here is:

 * Once a topic branch forks from "master", "master" is never
   merged into it again (either directly or indirectly).

 * Once a topic branch is fully cooked and merged into "master",
   it is deleted.  If you need to build on top of it to correct
   earlier mistakes, a new topic branch is created by forking at
   the tip of the "master".  This is not strictly necessary, but
   it makes it easier to keep your history simple.

 * Whenever you need to test or publish your changes to topic
   branches, merge them into "next" branch.

The script, being an example, hardcodes the publish branch name
to be "next", but it is trivial to make it configurable via
$GIT_DIR/config mechanism.

With this workflow, you would want to know:

(1) ... if a topic branch has ever been merged to "next".  Young
    topic branches can have stupid mistakes you would rather
    clean up before publishing, and things that have not been
    merged into other branches can be easily rebased without
    affecting other people.  But once it is published, you would
    not want to rewind it.

(2) ... if a topic branch has been fully merged to "master".
    Then you can delete it.  More importantly, you should not
    build on top of it -- other people may already want to
    change things related to the topic as patches against your
    "master", so if you need further changes, it is better to
    fork the topic (perhaps with the same name) afresh from the
    tip of "master".

Let's look at this example:

		   o---o---o---o---o---o---o---o---o---o "next"
		  /       /           /           /
		 /   a---a---b A     /           /
		/   /               /           /
	       /   /   c---c---c---c B         /
	      /   /   /             \         /
	     /   /   /   b---b C     \       /
	    /   /   /   /             \     /
    ---o---o---o---o---o---o---o---o---o---o---o "master"


A, B and C are topic branches.

 * A has one fix since it was merged up to "next".

 * B has finished.  It has been fully merged up to "master" and "next",
   and is ready to be deleted.

 * C has not merged to "next" at all.

We would want to allow C to be rebased, refuse A, and encourage
B to be deleted.

To compute (1):

	git rev-list ^master ^topic next
	git rev-list ^master        next

	if these match, topic has not merged in next at all.

To compute (2):

	git rev-list master..topic

	if this is empty, it is fully merged to "master".

DOC_END

================
File: project/.git/hooks/pre-receive.sample
================
#!/bin/sh
#
# An example hook script to make use of push options.
# The example simply echoes all push options that start with 'echoback='
# and rejects all pushes when the "reject" push option is used.
#
# To enable this hook, rename this file to "pre-receive".

if test -n "$GIT_PUSH_OPTION_COUNT"
then
	i=0
	while test "$i" -lt "$GIT_PUSH_OPTION_COUNT"
	do
		eval "value=\$GIT_PUSH_OPTION_$i"
		case "$value" in
		echoback=*)
			echo "echo from the pre-receive-hook: ${value#*=}" >&2
			;;
		reject)
			exit 1
		esac
		i=$((i + 1))
	done
fi

================
File: project/.git/hooks/prepare-commit-msg.sample
================
#!/bin/sh
#
# An example hook script to prepare the commit log message.
# Called by "git commit" with the name of the file that has the
# commit message, followed by the description of the commit
# message's source.  The hook's purpose is to edit the commit
# message file.  If the hook fails with a non-zero status,
# the commit is aborted.
#
# To enable this hook, rename this file to "prepare-commit-msg".

# This hook includes three examples. The first one removes the
# "# Please enter the commit message..." help message.
#
# The second includes the output of "git diff --name-status -r"
# into the message, just before the "git status" output.  It is
# commented because it doesn't cope with --amend or with squashed
# commits.
#
# The third example adds a Signed-off-by line to the message, that can
# still be edited.  This is rarely a good idea.

COMMIT_MSG_FILE=$1
COMMIT_SOURCE=$2
SHA1=$3

/usr/bin/perl -i.bak -ne 'print unless(m/^. Please enter the commit message/..m/^#$/)' "$COMMIT_MSG_FILE"

# case "$COMMIT_SOURCE,$SHA1" in
#  ,|template,)
#    /usr/bin/perl -i.bak -pe '
#       print "\n" . `git diff --cached --name-status -r`
# 	 if /^#/ && $first++ == 0' "$COMMIT_MSG_FILE" ;;
#  *) ;;
# esac

# SOB=$(git var GIT_COMMITTER_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# git interpret-trailers --in-place --trailer "$SOB" "$COMMIT_MSG_FILE"
# if test -z "$COMMIT_SOURCE"
# then
#   /usr/bin/perl -i.bak -pe 'print "\n" if !$first_line++' "$COMMIT_MSG_FILE"
# fi

================
File: project/.git/hooks/push-to-checkout.sample
================
#!/bin/sh

# An example hook script to update a checked-out tree on a git push.
#
# This hook is invoked by git-receive-pack(1) when it reacts to git
# push and updates reference(s) in its repository, and when the push
# tries to update the branch that is currently checked out and the
# receive.denyCurrentBranch configuration variable is set to
# updateInstead.
#
# By default, such a push is refused if the working tree and the index
# of the remote repository has any difference from the currently
# checked out commit; when both the working tree and the index match
# the current commit, they are updated to match the newly pushed tip
# of the branch. This hook is to be used to override the default
# behaviour; however the code below reimplements the default behaviour
# as a starting point for convenient modification.
#
# The hook receives the commit with which the tip of the current
# branch is going to be updated:
commit=$1

# It can exit with a non-zero status to refuse the push (when it does
# so, it must not modify the index or the working tree).
die () {
	echo >&2 "$*"
	exit 1
}

# Or it can make any necessary changes to the working tree and to the
# index to bring them to the desired state when the tip of the current
# branch is updated to the new commit, and exit with a zero status.
#
# For example, the hook can simply run git read-tree -u -m HEAD "$1"
# in order to emulate git fetch that is run in the reverse direction
# with git push, as the two-tree form of git read-tree -u -m is
# essentially the same as git switch or git checkout that switches
# branches while keeping the local changes in the working tree that do
# not interfere with the difference between the branches.

# The below is a more-or-less exact translation to shell of the C code
# for the default behaviour for git's push-to-checkout hook defined in
# the push_to_deploy() function in builtin/receive-pack.c.
#
# Note that the hook will be executed from the repository directory,
# not from the working tree, so if you want to perform operations on
# the working tree, you will have to adapt your code accordingly, e.g.
# by adding "cd .." or using relative paths.

if ! git update-index -q --ignore-submodules --refresh
then
	die "Up-to-date check failed"
fi

if ! git diff-files --quiet --ignore-submodules --
then
	die "Working directory has unstaged changes"
fi

# This is a rough translation of:
#
#   head_has_history() ? "HEAD" : EMPTY_TREE_SHA1_HEX
if git cat-file -e HEAD 2>/dev/null
then
	head=HEAD
else
	head=$(git hash-object -t tree --stdin </dev/null)
fi

if ! git diff-index --quiet --cached --ignore-submodules $head --
then
	die "Working directory has staged changes"
fi

if ! git read-tree -u -m "$commit"
then
	die "Could not update working tree to new HEAD"
fi

================
File: project/.git/hooks/sendemail-validate.sample
================
#!/bin/sh

# An example hook script to validate a patch (and/or patch series) before
# sending it via email.
#
# The hook should exit with non-zero status after issuing an appropriate
# message if it wants to prevent the email(s) from being sent.
#
# To enable this hook, rename this file to "sendemail-validate".
#
# By default, it will only check that the patch(es) can be applied on top of
# the default upstream branch without conflicts in a secondary worktree. After
# validation (successful or not) of the last patch of a series, the worktree
# will be deleted.
#
# The following config variables can be set to change the default remote and
# remote ref that are used to apply the patches against:
#
#   sendemail.validateRemote (default: origin)
#   sendemail.validateRemoteRef (default: HEAD)
#
# Replace the TODO placeholders with appropriate checks according to your
# needs.

validate_cover_letter () {
	file="$1"
	# TODO: Replace with appropriate checks (e.g. spell checking).
	true
}

validate_patch () {
	file="$1"
	# Ensure that the patch applies without conflicts.
	git am -3 "$file" || return
	# TODO: Replace with appropriate checks for this patch
	# (e.g. checkpatch.pl).
	true
}

validate_series () {
	# TODO: Replace with appropriate checks for the whole series
	# (e.g. quick build, coding style checks, etc.).
	true
}

# main -------------------------------------------------------------------------

if test "$GIT_SENDEMAIL_FILE_COUNTER" = 1
then
	remote=$(git config --default origin --get sendemail.validateRemote) &&
	ref=$(git config --default HEAD --get sendemail.validateRemoteRef) &&
	worktree=$(mktemp --tmpdir -d sendemail-validate.XXXXXXX) &&
	git worktree add -fd --checkout "$worktree" "refs/remotes/$remote/$ref" &&
	git config --replace-all sendemail.validateWorktree "$worktree"
else
	worktree=$(git config --get sendemail.validateWorktree)
fi || {
	echo "sendemail-validate: error: failed to prepare worktree" >&2
	exit 1
}

unset GIT_DIR GIT_WORK_TREE
cd "$worktree" &&

if grep -q "^diff --git " "$1"
then
	validate_patch "$1"
else
	validate_cover_letter "$1"
fi &&

if test "$GIT_SENDEMAIL_FILE_COUNTER" = "$GIT_SENDEMAIL_FILE_TOTAL"
then
	git config --unset-all sendemail.validateWorktree &&
	trap 'git worktree remove -ff "$worktree"' EXIT &&
	validate_series
fi

================
File: project/.git/hooks/update.sample
================
#!/bin/sh
#
# An example hook script to block unannotated tags from entering.
# Called by "git receive-pack" with arguments: refname sha1-old sha1-new
#
# To enable this hook, rename this file to "update".
#
# Config
# ------
# hooks.allowunannotated
#   This boolean sets whether unannotated tags will be allowed into the
#   repository.  By default they won't be.
# hooks.allowdeletetag
#   This boolean sets whether deleting tags will be allowed in the
#   repository.  By default they won't be.
# hooks.allowmodifytag
#   This boolean sets whether a tag may be modified after creation. By default
#   it won't be.
# hooks.allowdeletebranch
#   This boolean sets whether deleting branches will be allowed in the
#   repository.  By default they won't be.
# hooks.denycreatebranch
#   This boolean sets whether remotely creating branches will be denied
#   in the repository.  By default this is allowed.
#

# --- Command line
refname="$1"
oldrev="$2"
newrev="$3"

# --- Safety check
if [ -z "$GIT_DIR" ]; then
	echo "Don't run this script from the command line." >&2
	echo " (if you want, you could supply GIT_DIR then run" >&2
	echo "  $0 <ref> <oldrev> <newrev>)" >&2
	exit 1
fi

if [ -z "$refname" -o -z "$oldrev" -o -z "$newrev" ]; then
	echo "usage: $0 <ref> <oldrev> <newrev>" >&2
	exit 1
fi

# --- Config
allowunannotated=$(git config --type=bool hooks.allowunannotated)
allowdeletebranch=$(git config --type=bool hooks.allowdeletebranch)
denycreatebranch=$(git config --type=bool hooks.denycreatebranch)
allowdeletetag=$(git config --type=bool hooks.allowdeletetag)
allowmodifytag=$(git config --type=bool hooks.allowmodifytag)

# check for no description
projectdesc=$(sed -e '1q' "$GIT_DIR/description")
case "$projectdesc" in
"Unnamed repository"* | "")
	echo "*** Project description file hasn't been set" >&2
	exit 1
	;;
esac

# --- Check types
# if $newrev is 0000...0000, it's a commit to delete a ref.
zero=$(git hash-object --stdin </dev/null | tr '[0-9a-f]' '0')
if [ "$newrev" = "$zero" ]; then
	newrev_type=delete
else
	newrev_type=$(git cat-file -t $newrev)
fi

case "$refname","$newrev_type" in
	refs/tags/*,commit)
		# un-annotated tag
		short_refname=${refname##refs/tags/}
		if [ "$allowunannotated" != "true" ]; then
			echo "*** The un-annotated tag, $short_refname, is not allowed in this repository" >&2
			echo "*** Use 'git tag [ -a | -s ]' for tags you want to propagate." >&2
			exit 1
		fi
		;;
	refs/tags/*,delete)
		# delete tag
		if [ "$allowdeletetag" != "true" ]; then
			echo "*** Deleting a tag is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/tags/*,tag)
		# annotated tag
		if [ "$allowmodifytag" != "true" ] && git rev-parse $refname > /dev/null 2>&1
		then
			echo "*** Tag '$refname' already exists." >&2
			echo "*** Modifying a tag is not allowed in this repository." >&2
			exit 1
		fi
		;;
	refs/heads/*,commit)
		# branch
		if [ "$oldrev" = "$zero" -a "$denycreatebranch" = "true" ]; then
			echo "*** Creating a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/heads/*,delete)
		# delete branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/remotes/*,commit)
		# tracking branch
		;;
	refs/remotes/*,delete)
		# delete tracking branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a tracking branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	*)
		# Anything else (is there anything else?)
		echo "*** Update hook: unknown type of update to ref $refname of type $newrev_type" >&2
		exit 1
		;;
esac

# --- Finished
exit 0

================
File: project/.git/info/exclude
================
# git ls-files --others --exclude-from=.git/info/exclude
# Lines that start with '#' are comments.
# For a project mostly in C, the following would be a good set of
# exclude patterns (uncomment them if you want to use them):
# *.[oa]
# *~

================
File: project/.git/logs/HEAD
================
0000000000000000000000000000000000000000 47043769742782a886dac80d2d2ff5aa5be95780 cogspa <cogspa@yahoo.com> 1733243155 -0800	commit (initial): Initial commit: Face tracking app with camera selection
47043769742782a886dac80d2d2ff5aa5be95780 21b77ba88f2b582be93cee30433a1c8bf7a003eb cogspa <cogspa@yahoo.com> 1733247966 -0800	commit: Improved face mesh tracking: Fixed alignment, increased size, and added dynamic scaling
21b77ba88f2b582be93cee30433a1c8bf7a003eb d195c0db4bbaea2965a7f24a67179939c3e6f50b cogspa <cogspa@yahoo.com> 1733249794 -0800	commit: Fixed video and overlay flipping issues for better tracking alignment
d195c0db4bbaea2965a7f24a67179939c3e6f50b d195c0db4bbaea2965a7f24a67179939c3e6f50b cogspa <cogspa@yahoo.com> 1733256555 -0800	reset: moving to HEAD

================
File: project/.git/logs/refs/heads/master
================
0000000000000000000000000000000000000000 47043769742782a886dac80d2d2ff5aa5be95780 cogspa <cogspa@yahoo.com> 1733243155 -0800	commit (initial): Initial commit: Face tracking app with camera selection
47043769742782a886dac80d2d2ff5aa5be95780 21b77ba88f2b582be93cee30433a1c8bf7a003eb cogspa <cogspa@yahoo.com> 1733247966 -0800	commit: Improved face mesh tracking: Fixed alignment, increased size, and added dynamic scaling
21b77ba88f2b582be93cee30433a1c8bf7a003eb d195c0db4bbaea2965a7f24a67179939c3e6f50b cogspa <cogspa@yahoo.com> 1733249794 -0800	commit: Fixed video and overlay flipping issues for better tracking alignment

================
File: project/.git/logs/refs/remotes/origin/main
================
0000000000000000000000000000000000000000 e4437efb1e6095ca7e712cd4395a36d0bbdb259f cogspa <cogspa@yahoo.com> 1733250120 -0800	fetch: storing head
e4437efb1e6095ca7e712cd4395a36d0bbdb259f 6b4bffaeee36d6f10fe59dad174147cab6bf7e09 cogspa <cogspa@yahoo.com> 1733447892 -0800	fetch: fast-forward
6b4bffaeee36d6f10fe59dad174147cab6bf7e09 44f8dae57498db903d6b7e2b9c09f3b81e9ab9ec cogspa <cogspa@yahoo.com> 1733492417 -0800	fetch: fast-forward
44f8dae57498db903d6b7e2b9c09f3b81e9ab9ec e583ca9ed7b4f6f45fca9b83bcd3e288c8eb8ea2 cogspa <cogspa@yahoo.com> 1733494810 -0800	fetch: fast-forward

================
File: project/.git/logs/refs/remotes/origin/master
================
0000000000000000000000000000000000000000 21b77ba88f2b582be93cee30433a1c8bf7a003eb cogspa <cogspa@yahoo.com> 1733248261 -0800	update by push
21b77ba88f2b582be93cee30433a1c8bf7a003eb d195c0db4bbaea2965a7f24a67179939c3e6f50b cogspa <cogspa@yahoo.com> 1733249815 -0800	update by push

================
File: project/.git/logs/refs/stash
================
0000000000000000000000000000000000000000 928c727554aed92ba6af88f3f73cf096cd647dc6 cogspa <cogspa@yahoo.com> 1733256555 -0800	On master: temp_changes

================
File: project/.git/ORIG_HEAD
================
d195c0db4bbaea2965a7f24a67179939c3e6f50b

================
File: project/.git/refs/heads/master
================
d195c0db4bbaea2965a7f24a67179939c3e6f50b

================
File: project/.git/refs/remotes/origin/main
================
e583ca9ed7b4f6f45fca9b83bcd3e288c8eb8ea2

================
File: project/.git/refs/remotes/origin/master
================
d195c0db4bbaea2965a7f24a67179939c3e6f50b

================
File: project/.git/refs/stash
================
928c727554aed92ba6af88f3f73cf096cd647dc6

================
File: project/.gitignore
================
node_modules

================
File: project/index.html
================
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face and Hand Tracking with Custom Overlays</title>
    <style>
        body {
            margin: 0;
            padding: 20px;
            background: #1a1a1a;
            color: white;
            font-family: Arial, sans-serif;
        }
        .container {
            position: relative;
            width: fit-content;
            margin: 0 auto;
        }
        #video {
            transform: scaleX(-1);
        }
        #canvas {
            position: absolute;
            left: 0;
            top: 0;
            transform: scaleX(-1);
        }
        .controls {
            margin: 20px 0;
            padding: 20px;
            background: #2a2a2a;
            border-radius: 8px;
            display: flex;
            flex-direction: column;
            gap: 15px;
            max-width: 640px;
            margin: 20px auto;
        }
        .camera-select {
            padding: 8px;
            background: #333;
            color: white;
            border: 1px solid #444;
            border-radius: 4px;
            cursor: pointer;
        }
        .upload-section {
            display: flex;
            flex-direction: column;
            gap: 10px;
        }
        .upload-row {
            display: flex;
            align-items: center;
            gap: 10px;
        }
        label {
            min-width: 120px;
        }
        .preview-image {
            max-width: 100px;
            max-height: 100px;
            display: none;
            margin-left: 10px;
        }
        #status {
            text-align: center;
            margin: 10px 0;
            padding: 10px;
            background: #333;
            border-radius: 4px;
        }
        input[type="file"] {
            padding: 8px;
            background: #333;
            border: 1px solid #444;
            border-radius: 4px;
            color: white;
        }
        input[type="number"] {
            width: 60px;
            padding: 4px;
            background: #333;
            border: 1px solid #444;
            border-radius: 4px;
            color: white;
        }
    </style>
</head>
<body>
    <div class="controls">
        <select id="cameraSelect" class="camera-select">
            <option value="">Loading cameras...</option>
        </select>
        
        <div class="upload-section">
            <div class="upload-row">
                <label>Face Overlay:</label>
                <input type="file" id="faceOverlayUpload" accept="image/*">
                <img id="facePreview" class="preview-image">
                <input type="number" id="faceScale" value="1.0" step="0.1" min="0.1" max="5.0">
            </div>
            <div class="upload-row">
                <label>Hand Overlay:</label>
                <input type="file" id="handOverlayUpload" accept="image/*">
                <img id="handPreview" class="preview-image">
                <input type="number" id="handScale" value="1.0" step="0.1" min="0.1" max="5.0">
            </div>
        </div>
        
        <div id="status">Loading...</div>
    </div>
    <div class="container">
        <video id="video" width="640" height="480" autoplay playsinline></video>
        <canvas id="canvas"></canvas>
    </div>
    
    <script type="module" src="/main.js"></script>
</body>
</html>

================
File: project/index.js
================
// run `node index.js` in the terminal

console.log(`Hello Node.js v${process.versions.node}!`);

================
File: project/main.js
================
import * as tf from '@tensorflow/tfjs';
import '@tensorflow/tfjs-backend-webgl';
import * as faceLandmarksDetection from '@tensorflow-models/face-landmarks-detection';
import * as handPoseDetection from '@tensorflow-models/hand-pose-detection';

// Global variables
let detector = null;
let handDetector = null;
let video = null;
let canvas = null;
let ctx = null;
let isTracking = false;
let currentStream = null;

// Overlay images
let faceOverlay = null;
let handOverlay = null;
let faceScale = 1.0;
let handScale = 1.0;

// Simplified drawing function without manual flipping
function drawImageOnLandmarks(img, landmarks, scale) {
    if (!img || !landmarks || landmarks.length < 2) {
        console.log('Missing required data for overlay:', {
            hasImage: !!img,
            landmarksLength: landmarks?.length
        });
        return;
    }

    // Calculate bounding box
    let minX = Infinity, minY = Infinity;
    let maxX = -Infinity, maxY = -Infinity;

    landmarks.forEach(point => {
        const x = point.x;
        const y = point.y;
        minX = Math.min(minX, x);
        minY = Math.min(minY, y);
        maxX = Math.max(maxX, x);
        maxY = Math.max(maxY, y);
    });

    // Log bounding box coordinates for debugging
    console.log('Bounding box:', { minX, minY, maxX, maxY });

    const width = (maxX - minX) * scale;
    const height = (maxY - minY) * scale;
    const centerX = (minX + maxX) / 2;
    const centerY = (minY + maxY) / 2;

    console.log('Drawing dimensions:', { width, height, centerX, centerY, scale });

    try {
        // Draw a debug rectangle to show bounding box
        ctx.save();
        ctx.strokeStyle = 'red';
        ctx.lineWidth = 2;
        ctx.strokeRect(minX, minY, maxX - minX, maxY - minY);

        // Draw the overlay image
        ctx.translate(centerX, centerY);
        ctx.drawImage(img, -width / 2, -height / 2, width, height);
        ctx.restore();
        
        console.log('Overlay drawn successfully');
    } catch (error) {
        console.error('Error drawing overlay:', error);
    }
}

async function detectFaces() {
    if (!detector || !video || !canvas || !ctx || !isTracking) {
        console.log('Detection skipped - missing components');
        return;
    }
    
    try {
        if (video.readyState !== 4) {
            requestAnimationFrame(detectFaces);
            return;
        }

        // Log video dimensions for debugging
        console.log('Video dimensions:', {
            width: video.videoWidth,
            height: video.videoHeight,
            canvasWidth: canvas.width,
            canvasHeight: canvas.height
        });

        const predictions = await detector.estimateFaces(video, {
            flipHorizontal: false,  // Changed to true since we're using CSS transform
            staticImageMode: false,
            predictIrises: false
        });
        
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        
        if (predictions.length > 0) {
            predictions.forEach(prediction => {
                const keypoints = prediction.keypoints;
                
                if (faceOverlay) {
                    console.log('Drawing face overlay with', keypoints.length, 'keypoints');
                    drawImageOnLandmarks(faceOverlay, keypoints, faceScale);
                } else {
                    // Draw keypoints for debugging
                    ctx.fillStyle = '#00FF00';
                    ctx.strokeStyle = '#00FF00';
                    ctx.lineWidth = 1.5;
                    
                    keypoints.forEach(point => {
                        ctx.beginPath();
                        ctx.arc(point.x, point.y, 2.5, 0, 2 * Math.PI);
                        ctx.fill();
                    });
                }
            });
        } else {
            console.log('No faces detected');
        }
    } catch (error) {
        console.error('Error in face detection:', error);
    }
    
    requestAnimationFrame(detectFaces);
}

async function detectHands() {
    if (!handDetector || !video || !canvas || !ctx || !isTracking) return;
    
    try {
        if (video.readyState !== 4) {
            requestAnimationFrame(detectHands);
            return;
        }

        const hands = await handDetector.estimateHands(video, {
            flipHorizontal: true
        });
        
        if (hands.length > 0) {
            hands.forEach(hand => {
                if (handOverlay) {
                    drawImageOnLandmarks(handOverlay, hand.keypoints, handScale);
                } else {
                    ctx.fillStyle = '#00FFFF';
                    ctx.strokeStyle = '#00FFFF';
                    ctx.lineWidth = 2;
                    
                    hand.keypoints.forEach(point => {
                        ctx.beginPath();
                        ctx.arc(point.x, point.y, 3, 0, 2 * Math.PI);
                        ctx.fill();
                    });
                }
            });
        }
        
        if (isTracking) {
            requestAnimationFrame(detectHands);
        }
    } catch (error) {
        console.error('Error during detection:', error);
        updateStatus('Error during detection: ' + error.message);
        if (isTracking) {
            setTimeout(detectHands, 1000);
        }
    }
}

async function init() {
    try {
        updateStatus('Initializing...');
        
        // Optimize TensorFlow.js initialization
        await tf.ready();
        await tf.setBackend('webgl');
        tf.env().set('WEBGL_FORCE_F16_TEXTURES', true);
        tf.env().set('WEBGL_PACK', true);
        console.log('TensorFlow.js backend initialized:', tf.getBackend());
        
        // Initialize video element
        video = document.getElementById('video');
        if (!video) throw new Error('Video element not found');
        
        // Initialize canvas
        canvas = document.getElementById('canvas');
        if (!canvas) throw new Error('Canvas element not found');
        ctx = canvas.getContext('2d');
        if (!ctx) throw new Error('Could not get canvas context');
        
        // Set up camera stream
        await setupCamera();
        
        // Set up canvas dimensions
        canvas.width = video.width;
        canvas.height = video.height;
        
        // Setup image upload handlers
        setupImageUploads();
        console.log('Image upload handlers initialized');
        
        // Load models in parallel
        updateStatus('Loading detection models...');
        const [faceModel, handModel] = await Promise.all([
            setupFaceDetector(),
            setupHandDetector()
        ]);
        
        console.log('Models loaded successfully');
        updateStatus('Ready!');
        
        // Start tracking
        isTracking = true;
        detectFaces();
        detectHands();
        
    } catch (error) {
        console.error('Initialization error:', error);
        updateStatus('Error: ' + error.message);
    }
}

// Setup image upload handlers
function setupImageUploads() {
    console.log('Setting up image uploads...');
    
    const faceInput = document.getElementById('faceOverlayUpload');
    const handInput = document.getElementById('handOverlayUpload');
    const facePreview = document.getElementById('facePreview');
    const handPreview = document.getElementById('handPreview');
    const faceScaleInput = document.getElementById('faceScale');
    const handScaleInput = document.getElementById('handScale');

    if (!faceInput || !handInput || !facePreview || !handPreview) {
        console.error('Missing required DOM elements for image uploads');
        return;
    }

    faceInput.addEventListener('change', async (e) => {
        if (e.target.files && e.target.files[0]) {
            const file = e.target.files[0];
            const img = new Image();
            img.src = URL.createObjectURL(file);
            
            try {
                await new Promise((resolve, reject) => {
                    img.onload = () => {
                        console.log('Face overlay loaded:', {
                            width: img.width,
                            height: img.height,
                            src: img.src
                        });
                        faceOverlay = img;
                        facePreview.src = img.src;
                        facePreview.style.display = 'block';
                        resolve();
                    };
                    img.onerror = () => reject(new Error('Failed to load face overlay'));
                });
            } catch (error) {
                console.error('Error loading face overlay:', error);
                updateStatus('Error loading face overlay');
            }
        }
    });

    handInput.addEventListener('change', async (e) => {
        if (e.target.files && e.target.files[0]) {
            const file = e.target.files[0];
            const img = new Image();
            img.src = URL.createObjectURL(file);
            await new Promise(resolve => {
                img.onload = () => {
                    console.log('Hand overlay loaded:', img.width, 'x', img.height);
                    handOverlay = img;
                    handPreview.src = img.src;
                    handPreview.style.display = 'block';
                    resolve();
                };
                img.onerror = () => {
                    console.error('Error loading hand overlay');
                    updateStatus('Error loading hand overlay');
                };
            });
        }
    });

    faceScaleInput.addEventListener('input', (e) => {
        const newScale = parseFloat(e.target.value);
        if (!isNaN(newScale) && newScale > 0) {
            faceScale = newScale;
            console.log('Face scale updated:', faceScale);
        }
    });

    handScaleInput.addEventListener('input', (e) => {
        handScale = parseFloat(e.target.value);
        console.log('Hand scale updated:', handScale);
    });
}

async function getConnectedCameras() {
    try {
        const devices = await navigator.mediaDevices.enumerateDevices();
        return devices.filter(device => device.kind === 'videoinput');
    } catch (error) {
        console.error('Error getting cameras:', error);
        updateStatus('Error: Could not get camera list');
        return [];
    }
}

async function populateCameraSelect() {
    try {
        const cameraSelect = document.getElementById('cameraSelect');
        const cameras = await getConnectedCameras();
        
        // Clear existing options
        cameraSelect.innerHTML = '';
        
        if (cameras.length === 0) {
            const option = document.createElement('option');
            option.text = 'No cameras found';
            cameraSelect.add(option);
            cameraSelect.disabled = true;
            throw new Error('No cameras found');
        }

        // Add options for each camera
        cameras.forEach(camera => {
            const option = document.createElement('option');
            option.value = camera.deviceId;
            option.text = camera.label || `Camera ${cameraSelect.length + 1}`;
            cameraSelect.add(option);
        });

        // Enable select and add change listener
        cameraSelect.disabled = false;
        cameraSelect.onchange = async (event) => {
            try {
                updateStatus('Switching camera...');
                await switchCamera(event.target.value);
            } catch (error) {
                console.error('Error in camera switch:', error);
                updateStatus('Failed to switch camera. Please try again.');
            }
        };

        console.log('Camera select populated with', cameras.length, 'cameras');
    } catch (error) {
        console.error('Error populating camera select:', error);
        updateStatus('Error: Could not list cameras - ' + error.message);
    }
}

async function switchCamera(deviceId) {
    try {
        // Stop tracking before switching camera
        isTracking = false;

        // Stop all tracks of the current stream if it exists
        if (currentStream) {
            const tracks = currentStream.getTracks();
            tracks.forEach(track => {
                track.stop();
                currentStream.removeTrack(track);
            });
            currentStream = null;
        }

        // Clear video source
        if (video.srcObject) {
            video.srcObject = null;
        }

        // Wait a moment for cleanup
        await new Promise(resolve => setTimeout(resolve, 500));

        // Configure new camera
        const constraints = {
            video: {
                deviceId: deviceId ? { exact: deviceId } : undefined,
                width: 640,
                height: 480
            }
        };

        // Get new stream
        const stream = await navigator.mediaDevices.getUserMedia(constraints);
        
        // Update video source
        video.srcObject = stream;
        currentStream = stream;

        // Wait for video to be ready
        await new Promise((resolve) => {
            video.onloadedmetadata = () => {
                video.play()
                    .then(() => {
                        console.log('New camera stream started');
                        resolve();
                    })
                    .catch(error => {
                        console.error('Error playing video:', error);
                        throw error;
                    });
            };
        });

        // Restart tracking
        isTracking = true;
        detectFaces();
        detectHands();
        
        updateStatus('Camera switched successfully');
    } catch (error) {
        console.error('Error switching camera:', error);
        updateStatus('Error: Could not switch camera - ' + error.message);
        
        // Try to recover the previous stream if possible
        if (!currentStream) {
            try {
                const cameras = await getConnectedCameras();
                if (cameras.length > 0) {
                    await switchCamera(cameras[0].deviceId);
                }
            } catch (recoveryError) {
                console.error('Recovery failed:', recoveryError);
            }
        }
    }
}

async function setupCamera() {
    try {
        // Initialize video element if not already done
        if (!video) {
            video = document.getElementById('video');
            if (!video) {
                throw new Error('Video element not found');
            }
        }

        // Get list of cameras
        const cameras = await getConnectedCameras();
        if (cameras.length === 0) {
            throw new Error('No cameras found');
        }

        // Set up camera selection
        await populateCameraSelect();

        // Start with first camera if no stream exists
        if (!currentStream) {
            await switchCamera(cameras[0].deviceId);
        }

        console.log('Camera setup complete');
        updateStatus('Camera ready');
        return true;
    } catch (error) {
        console.error('Error setting up camera:', error);
        updateStatus('Error: Camera setup failed - ' + error.message);
        throw error;
    }
}

// Helper function to check if a device is in use
async function isDeviceInUse(deviceId) {
    try {
        const stream = await navigator.mediaDevices.getUserMedia({
            video: { deviceId: { exact: deviceId } }
        });
        stream.getTracks().forEach(track => track.stop());
        return false;
    } catch (error) {
        return error.name === 'NotReadableError' || error.name === 'TrackStartError';
    }
}

async function setupCanvas() {
    try {
        // Make sure canvas and video elements exist
        canvas = document.getElementById('canvas');
        if (!canvas) {
            throw new Error('Canvas element not found');
        }

        ctx = canvas.getContext('2d');
        if (!ctx) {
            throw new Error('Could not get canvas context');
        }

        // Make sure video element exists and is properly sized
        if (!video) {
            throw new Error('Video element not initialized');
        }

        // Set canvas dimensions
        canvas.width = video.width || 640;
        canvas.height = video.height || 480;
        
        // Set canvas position
        canvas.style.position = 'absolute';
        canvas.style.left = '0';
        canvas.style.top = '0';
        
        // Reset any previous transformations
        ctx.setTransform(1, 0, 0, 1, 0, 0);
        
        console.log('Canvas setup complete with dimensions:', canvas.width, 'x', canvas.height);
        updateStatus('Canvas setup complete');
        return true;
    } catch (error) {
        console.error('Error setting up canvas:', error);
        updateStatus('Error: Canvas setup failed - ' + error.message);
        throw error;
    }
}

async function setupFaceDetector() {
    try {
        const model = faceLandmarksDetection.SupportedModels.MediaPipeFaceMesh;
        const detectorConfig = {
            runtime: 'tfjs',
            maxFaces: 1,
            refineLandmarks: false,
            shouldLoadIrisModel: false,
            enableFaceGeometry: false,
            modelType: 'lite'  // Use lite model for faster loading
        };
        
        detector = await faceLandmarksDetection.createDetector(model, detectorConfig);
        console.log('Face detector created');
    } catch (error) {
        console.error('Error loading face detector:', error);
        throw error;
    }
}

async function setupHandDetector() {
    try {
        const model = handPoseDetection.SupportedModels.MediaPipeHands;
        const detectorConfig = {
            runtime: 'tfjs',
            maxHands: 2,
            modelType: 'lite'  // Use lite model for faster loading
        };
        
        handDetector = await handPoseDetection.createDetector(model, detectorConfig);
        console.log('Hand detector created');
    } catch (error) {
        console.error('Error loading hand detector:', error);
        throw error;
    }
}

function updateStatus(message) {
    const status = document.getElementById('status');
    status.textContent = message;
}

// Start the application when the page loads
window.addEventListener('load', init);

================
File: project/package.json
================
{
  "name": "face-tracking-app",
  "private": true,
  "version": "1.0.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "preview": "vite preview"
  },
  "dependencies": {
    "@tensorflow/tfjs": "^4.11.0",
    "@tensorflow/tfjs-backend-webgl": "^4.11.0",
    "@tensorflow/tfjs-core": "^4.11.0",
    "@tensorflow-models/face-landmarks-detection": "^1.0.5",
    "@tensorflow-models/hand-pose-detection": "^2.0.1"
  },
  "devDependencies": {
    "vite": "^4.4.9"
  }
}

================
File: project/postcss.config.js
================
export default {
  plugins: {
    tailwindcss: {},
    autoprefixer: {},
  },
}

================
File: project/README.md
================
# Face and Hand Tracking Web Application

A real-time web application for face and hand tracking with custom image overlays and interactive drawing capabilities.

## System Requirements

- Node.js (v14.0.0 or higher)
- Modern web browser with WebGL support (Chrome, Firefox, Edge recommended)
- Webcam
- GPU with WebGL support (for TensorFlow.js)

## Features

- Real-time face tracking
- Hand pose detection
- Custom image overlays
- Drawing canvas
- Green screen (chroma key) background removal
- Dynamic video backgrounds
- Responsive dark-themed UI

## Installation

1. Clone the repository:
```bash
git clone https://github.com/your-username/face-tracking-app.git
cd face-tracking-app
```

2. Install dependencies:
```bash
npm install
```

3. Start the development server:
```bash
npm run dev
```

4. Open your browser and navigate to the URL shown in the terminal (typically http://localhost:5173)

## Browser Permissions

The application requires the following permissions:
- Camera access
- JavaScript enabled
- WebGL enabled

## Development Setup

To modify or enhance the application:

1. Install development dependencies:
```bash
npm install --save-dev vite
```

2. Start development server with hot reload:
```bash
npm run dev
```

3. Build for production:
```bash
npm run build
```

4. Preview production build:
```bash
npm run preview
```

## Project Structure

```
project/
 index.html          # Main HTML file
 main.js            # Core application logic
 package.json       # Dependencies and scripts
 public/            # Static assets
```

## Dependencies

Core dependencies:
- @tensorflow/tfjs: ^4.11.0
- @tensorflow/tfjs-backend-webgl: ^4.11.0
- @tensorflow/tfjs-core: ^4.11.0
- @tensorflow-models/face-landmarks-detection: ^1.0.5
- @tensorflow-models/hand-pose-detection: ^2.0.1

Development dependencies:
- vite: ^4.4.9

## Troubleshooting

1. Camera not working:
   - Ensure camera permissions are granted in browser
   - Check if another application is using the camera
   - Try refreshing the page

2. Performance issues:
   - Ensure you have a GPU with WebGL support
   - Close other resource-intensive applications
   - Try reducing video resolution in settings

3. TensorFlow.js errors:
   - Clear browser cache and reload
   - Check for browser compatibility
   - Ensure WebGL is enabled

## Browser Compatibility

Tested and supported on:
- Chrome (latest)
- Firefox (latest)
- Edge (latest)

Note: Performance may vary based on hardware capabilities and browser implementation.

## Known Limitations

- Requires modern browser with WebGL support
- Performance dependent on client hardware
- May experience higher CPU/GPU usage during tracking
- Mobile performance may be limited

## License

[Your chosen license]

## Contributing

1. Fork the repository
2. Create your feature branch
3. Commit your changes
4. Push to the branch
5. Create a new Pull Request

================
File: project/src/camera-selector.js
================
export class CameraSelector {
  constructor() {
    this.devices = [];
  }

  async getAvailableCameras() {
    try {
      // Check if mediaDevices is supported
      if (!navigator.mediaDevices || !navigator.mediaDevices.enumerateDevices) {
        throw new Error('Media devices API not supported');
      }

      // Request permission with explicit video constraints
      const stream = await navigator.mediaDevices.getUserMedia({
        video: true,
        audio: false
      });

      // Stop the temporary stream immediately
      stream.getTracks().forEach(track => track.stop());
      
      // Now that we have permission, enumerate devices
      const devices = await navigator.mediaDevices.enumerateDevices();
      this.devices = devices.filter(device => device.kind === 'videoinput');
      
      return this.devices;
    } catch (error) {
      console.error('Error getting camera devices:', error);
      return [];
    }
  }

  createCameraSelect(container) {
    // Clear existing content
    container.innerHTML = '';
    
    const select = document.createElement('select');
    select.className = 'mt-2 px-4 py-2 bg-gray-800 rounded text-white';
    select.id = 'camera-select';
    
    if (this.devices.length === 0) {
      const option = document.createElement('option');
      option.value = '';
      option.text = 'No cameras found';
      select.appendChild(option);
      select.disabled = true;
    } else {
      this.devices.forEach((device, index) => {
        const option = document.createElement('option');
        option.value = device.deviceId;
        option.text = device.label || `Camera ${index + 1}`;
        select.appendChild(option);
      });
    }

    container.appendChild(select);
    return select;
  }
}

================
File: project/src/components/diagnostic-panel.js
================
import { CameraDiagnostics } from '../utils/diagnostics';

export class DiagnosticPanel {
  constructor(container) {
    this.container = container;
    this.panel = document.createElement('div');
    this.panel.className = 'bg-gray-800 p-4 rounded-lg mb-4';
    this.container.insertBefore(this.panel, this.container.firstChild);
  }

  async runDiagnostics() {
    this.panel.innerHTML = '<p class="text-yellow-400">Running diagnostics...</p>';

    // Check browser support
    const browserSupport = await CameraDiagnostics.checkBrowserSupport();
    const permissionStatus = await CameraDiagnostics.checkCameraPermission();
    const cameraStatus = await CameraDiagnostics.checkConnectedCameras();

    let html = '<div class="space-y-2">';
    
    // Browser Support Section
    html += '<div class="mb-3">';
    html += '<h3 class="font-bold mb-2">Browser Compatibility:</h3>';
    if (browserSupport.errors.length === 0) {
      html += '<p class="text-green-400"> Your browser fully supports all required features</p>';
    } else {
      html += '<div class="text-red-400">';
      browserSupport.errors.forEach(error => {
        html += `<p> ${error}</p>`;
      });
      html += '</div>';
    }
    html += '</div>';

    // Camera Permission Section
    html += '<div class="mb-3">';
    html += '<h3 class="font-bold mb-2">Camera Permission:</h3>';
    if (permissionStatus.granted) {
      html += '<p class="text-green-400"> Camera permission granted</p>';
    } else {
      html += `<p class="text-red-400"> ${permissionStatus.error}</p>`;
      if (permissionStatus.error === 'Camera permission denied') {
        html += `<p class="text-sm mt-1">To fix: Click the camera icon in your browser's address bar and allow access</p>`;
      }
    }
    html += '</div>';

    // Connected Cameras Section
    html += '<div class="mb-3">';
    html += '<h3 class="font-bold mb-2">Connected Cameras:</h3>';
    if (cameraStatus.found) {
      html += `<p class="text-green-400"> Found ${cameraStatus.count} camera${cameraStatus.count > 1 ? 's' : ''}</p>`;
    } else {
      html += `<p class="text-red-400"> ${cameraStatus.error || 'No cameras detected'}</p>`;
      html += '<p class="text-sm mt-1">Make sure a camera is properly connected to your computer</p>';
    }
    html += '</div>';

    this.panel.innerHTML = html;
  }
}

================
File: project/src/face-tracker.js
================
import * as tf from '@tensorflow/tfjs';
import '@tensorflow/tfjs-backend-webgl';
import '@mediapipe/face_mesh';
import * as faceLandmarksDetection from '@tensorflow-models/face-landmarks-detection';

export class FaceTracker {
  constructor(video, canvas) {
    this.video = video;
    this.canvas = canvas;
    this.ctx = canvas.getContext('2d');
    this.model = null;
    this.isTracking = false;
  }

  async initialize() {
    try {
      // Ensure TensorFlow.js is properly initialized with WebGL backend
      await tf.setBackend('webgl');
      await tf.ready();
      
      // Load the MediaPipe Facemesh model
      this.model = await faceLandmarksDetection.load(
        faceLandmarksDetection.SupportedPackages.mediapipeFacemesh,
        {
          maxFaces: 1,
          refineLandmarks: true,
          shouldLoadIrisModel: false
        }
      );
      
      return true;
    } catch (error) {
      console.error('Error loading face tracking model:', error);
      throw new Error('Failed to initialize face tracking model');
    }
  }

  async startTracking() {
    if (!this.model) {
      throw new Error('Face tracking model not initialized');
    }
    
    this.isTracking = true;
    this.track();
  }

  stopTracking() {
    this.isTracking = false;
    this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);
  }

  async track() {
    if (!this.isTracking) return;

    try {
      const faces = await this.model.estimateFaces({
        input: this.video,
        returnTensors: false,
        flipHorizontal: false
      });

      this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);
      
      faces.forEach(face => {
        // Draw face mesh points
        this.ctx.fillStyle = '#32CD32';
        face.keypoints.forEach(point => {
          this.ctx.beginPath();
          this.ctx.arc(point.x, point.y, 2, 0, 2 * Math.PI);
          this.ctx.fill();
        });

        // Draw face bounding box
        if (face.box) {
          this.ctx.strokeStyle = '#00ff00';
          this.ctx.lineWidth = 2;
          this.ctx.strokeRect(
            face.box.xMin,
            face.box.yMin,
            face.box.xMax - face.box.xMin,
            face.box.yMax - face.box.yMin
          );
        }
      });
    } catch (error) {
      console.error('Error during face tracking:', error);
    }

    if (this.isTracking) {
      requestAnimationFrame(() => this.track());
    }
  }
}

================
File: project/src/main.js
================
import { WebcamManager } from './webcam';
import { FaceTracker } from './face-tracker';
import { CameraSelector } from './camera-selector';
import { DiagnosticPanel } from './components/diagnostic-panel';

class App {
  constructor() {
    this.webcamManager = new WebcamManager();
    this.faceTracker = new FaceTracker(
      document.getElementById('webcam'),
      document.getElementById('overlay')
    );
    this.cameraSelector = new CameraSelector();
    
    this.startBtn = document.getElementById('startBtn');
    this.stopBtn = document.getElementById('stopBtn');
    this.cameraSelectContainer = document.getElementById('camera-select-container');
    
    // Create diagnostic panel
    const mainContainer = document.querySelector('.max-w-3xl');
    this.diagnosticPanel = new DiagnosticPanel(mainContainer);
    
    // Wait for DOM to be fully loaded
    if (document.readyState === 'loading') {
      document.addEventListener('DOMContentLoaded', () => this.init());
    } else {
      this.init();
    }
  }

  async init() {
    // Run diagnostics first
    await this.diagnosticPanel.runDiagnostics();
    await this.initializeCameras();
    this.setupEventListeners();
  }

  async initializeCameras() {
    try {
      const cameras = await this.cameraSelector.getAvailableCameras();
      if (cameras.length > 0) {
        const select = this.cameraSelector.createCameraSelect(this.cameraSelectContainer);
        select.addEventListener('change', () => {
          if (this.webcamManager.isActive()) {
            this.stop();
            this.start();
          }
        });
      } else {
        this.startBtn.disabled = true;
        this.cameraSelectContainer.innerHTML = '<p class="text-red-500">No cameras detected. Please connect a camera and refresh the page.</p>';
      }
    } catch (error) {
      console.error('Failed to initialize cameras:', error);
      this.startBtn.disabled = true;
      this.cameraSelectContainer.innerHTML = '<p class="text-red-500">Failed to access camera. Please ensure you have granted camera permissions.</p>';
    }
  }

  setupEventListeners() {
    this.startBtn.addEventListener('click', () => this.start());
    this.stopBtn.addEventListener('click', () => this.stop());
  }

  async start() {
    this.startBtn.disabled = true;
    
    const selectedCamera = document.getElementById('camera-select')?.value;
    const webcamStarted = await this.webcamManager.setup(selectedCamera);
    
    if (!webcamStarted) {
      alert('Failed to access webcam. Please ensure you have granted camera permissions.');
      this.startBtn.disabled = false;
      return;
    }

    const modelLoaded = await this.faceTracker.initialize();
    if (!modelLoaded) {
      alert('Failed to load face tracking model. Please try again.');
      this.webcamManager.stop();
      this.startBtn.disabled = false;
      return;
    }

    this.faceTracker.startTracking();
    this.stopBtn.disabled = false;
  }

  stop() {
    this.faceTracker.stopTracking();
    this.webcamManager.stop();
    this.startBtn.disabled = false;
    this.stopBtn.disabled = true;
  }
}

// Initialize the application
new App();

================
File: project/src/style.css
================
@tailwind base;
@tailwind components;
@tailwind utilities;

================
File: project/src/utils/diagnostics.js
================
export class CameraDiagnostics {
  static async checkBrowserSupport() {
    const results = {
      mediaDevicesSupported: false,
      getUserMediaSupported: false,
      enumerateDevicesSupported: false,
      errors: []
    };

    // Check MediaDevices API support
    if (!navigator.mediaDevices) {
      results.errors.push('MediaDevices API is not supported in your browser');
      return results;
    }
    results.mediaDevicesSupported = true;

    // Check getUserMedia support
    if (!navigator.mediaDevices.getUserMedia) {
      results.errors.push('getUserMedia is not supported in your browser');
      return results;
    }
    results.getUserMediaSupported = true;

    // Check enumerateDevices support
    if (!navigator.mediaDevices.enumerateDevices) {
      results.errors.push('enumerateDevices is not supported in your browser');
      return results;
    }
    results.enumerateDevicesSupported = true;

    return results;
  }

  static async checkCameraPermission() {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      stream.getTracks().forEach(track => track.stop());
      return { granted: true };
    } catch (error) {
      return {
        granted: false,
        error: error.name === 'NotAllowedError' ? 'Camera permission denied' :
               error.name === 'NotFoundError' ? 'No camera detected' :
               'Failed to access camera'
      };
    }
  }

  static async checkConnectedCameras() {
    try {
      const devices = await navigator.mediaDevices.enumerateDevices();
      const cameras = devices.filter(device => device.kind === 'videoinput');
      return {
        found: cameras.length > 0,
        count: cameras.length,
        devices: cameras
      };
    } catch (error) {
      return {
        found: false,
        count: 0,
        error: 'Failed to enumerate camera devices'
      };
    }
  }
}

================
File: project/src/webcam.js
================
export class WebcamManager {
  constructor() {
    this.video = document.getElementById('webcam');
    this.stream = null;
  }

  async setup(deviceId = null) {
    try {
      // Stop any existing stream
      this.stop();

      const constraints = {
        video: deviceId ? 
          {
            deviceId: { exact: deviceId },
            width: { ideal: 640 },
            height: { ideal: 480 }
          } : 
          {
            width: { ideal: 640 },
            height: { ideal: 480 }
          },
        audio: false
      };

      this.stream = await navigator.mediaDevices.getUserMedia(constraints);
      this.video.srcObject = this.stream;
      
      // Wait for video metadata to be loaded before setting canvas dimensions
      await new Promise((resolve) => {
        this.video.onloadedmetadata = () => {
          const canvas = document.getElementById('overlay');
          canvas.width = this.video.videoWidth;
          canvas.height = this.video.videoHeight;
          resolve();
        };
      });
      
      return true;
    } catch (error) {
      console.error('Error accessing webcam:', error);
      return false;
    }
  }

  stop() {
    if (this.stream) {
      this.stream.getTracks().forEach(track => track.stop());
      this.video.srcObject = null;
      this.stream = null;
    }
  }

  isActive() {
    return !!this.stream;
  }
}

================
File: project/tailwind.config.js
================
/** @type {import('tailwindcss').Config} */
export default {
  content: [
    "./index.html",
    "./src/**/*.{js,ts,jsx,tsx}",
  ],
  theme: {
    extend: {},
  },
  plugins: [],
}
